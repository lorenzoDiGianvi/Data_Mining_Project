{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train_Attrition_Cat.csv',sep=';')\n",
    "#train = df.drop(columns=['BusinessTravel','EducationField', 'MaritalStatus','JobRole'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoders = dict()\n",
    "column2encode = ['BusinessTravel', 'Department', 'EducationField', 'MaritalStatus','JobRole']\n",
    "\n",
    "for col in column2encode:\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in df.columns if col != 'Attrition']\n",
    "X_train = df[attributes].values\n",
    "y_train = df['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = pd.read_csv('Test_pulito.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "Label_encoders = dict()\n",
    "column2encode = ['BusinessTravel', 'Department', 'EducationField', 'MaritalStatus','JobRole']\n",
    "\n",
    "for col in column2encode:\n",
    "    le = LabelEncoder()\n",
    "    test_set[col] = le.fit_transform(test_set[col])\n",
    "    label_encoders[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes = [col for col in test_set.columns if col != 'Attrition']\n",
    "X_test = test_set[attributes].values\n",
    "y_test = test_set['Attrition']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(criterion='gini', max_depth=None, \n",
    "                             #il minimo splitting di almeno due esempi, min_leaf = min numb di esempi che si richiede iin una foglia\n",
    "                             min_samples_split=2, min_samples_leaf=1)\n",
    "#passiamo il training e le labels, citraro dice meglio usare la gini, focalizzaraci su max e min split\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(results, n_top=3):\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = {'min_samples_split': [2, 5, 10, 20],\n",
    "              'min_samples_leaf': [1, 5, 10, 20],\n",
    "             }\n",
    "\n",
    "grid_search = GridSearchCV(clf, param_grid=param_list)\n",
    "grid_search.fit(X_train, y_train)\n",
    "clf = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = {'max_depth': [None] + list(np.arange(2, 20)),\n",
    "              'min_samples_split': [2, 5, 10, 20, 30, 50, 100],\n",
    "              'min_samples_leaf': [1, 5, 10, 20, 30, 50, 100],\n",
    "             }\n",
    "\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_list, \n",
    "                                   n_iter=100)\n",
    "random_search.fit(X_train, y_train)\n",
    "clf = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.809 (std: 0.020)\n",
      "Parameters: {'min_samples_leaf': 10, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.806 (std: 0.036)\n",
      "Parameters: {'min_samples_leaf': 20, 'min_samples_split': 2}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.806 (std: 0.036)\n",
      "Parameters: {'min_samples_leaf': 20, 'min_samples_split': 5}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.806 (std: 0.036)\n",
      "Parameters: {'min_samples_leaf': 20, 'min_samples_split': 10}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.806 (std: 0.036)\n",
      "Parameters: {'min_samples_leaf': 20, 'min_samples_split': 20}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(grid_search.cv_results_, n_top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.832 (std: 0.013)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 1, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 20, 'max_depth': 7}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 5, 'max_depth': 11}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 5, 'max_depth': 6}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 20, 'max_depth': 13}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 5, 'max_depth': 15}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.832 (std: 0.012)\n",
      "Parameters: {'min_samples_split': 100, 'min_samples_leaf': 10, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(random_search.cv_results_, n_top=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
